{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Document Analysis: Computational Methods - Summer Term 2025\n",
                "### Lectures: Jun.-Prof. Dr. Andreas Spitz\n",
                "### Tutorials: Julian Schelb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exercise 07"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### You will learn about:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Language Models\n",
                "- Contextualized Word Embeddings\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## Task 1: Terminology and Understanding:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Give a concise answers to each of the following questions.\n",
                "\n",
                "1. What is fine-tuning?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "2. What is the difference between static and contextualized word embeddings?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "3. Explain the purpose of the [SEP] token in BERT."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 2 - Contextualized Word Embeddings\n",
                "To avoid issues due to package inconsistencies, please i\n",
                "\n",
                "### Part 1:\n",
                "Use a pre-trained BERT model to extract word embeddings of the word \"bank\" from the following seven sentences. \n",
                "To extract the embeddings, identify the token that corresponds to \"bank\" in each sentence \n",
                "(keep in mind that token != word), then extract the hidden states for this token from the model's final four \n",
                "hidden layers (this is a tensor of dimension 4 x 768). \n",
                "Average these four states to obtain a single 768-dimensional embedding for the token \"bank\" in each sentence. \n",
                "\n",
                "\n",
                "1. It is good to always have money in the bank.\n",
                "2. A bank of fog came drifting in from the sea.\n",
                "3. Sadly, my piggy bank is empty.\n",
                "4. Gold frequently deposits on the bank of a river.\n",
                "5. Vast banks of clouds were visible on the horizon.\n",
                "6. The First Bank of the United States was chartered in 1791.\n",
                "7. The flight instructor told her to bank hard left.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
                        "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
                    ]
                }
            ],
            "source": [
                "# We use bert-base-uncased model from HuggingFace (https://huggingface.co/bert-base-uncased).\n",
                "from transformers import BertTokenizer, BertModel\n",
                "\n",
                "# BERT has its own specific tokenizer, you need to use it to tokenize the given sentences\n",
                "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
                "\n",
                "# And this is the language model; it consists of 12 layers. \n",
                "# You need to extract hidden-spaces for the \"bank\" token from the last four layers and then average them.\n",
                "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
                "\n",
                "# TODO ADD YOUR CODE HERE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "\n",
                "---\n",
                "\n",
                "#### Part 2:\n",
                "\n",
                "Visualize your results by computing a suitable 2-dimensional projection of the seven embeddings (e.g., by using PCA, t-SNE, or UMAP). \n",
                "Make sure that each embedding is labeled clearly in the plot with the sentence number from which you extracted it.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# You need to use **one** of the dimensionality reduction techniques:\n",
                "\n",
                "# for PCA use:\n",
                "# from sklearn.decomposition import PCA\n",
                "\n",
                "# for t-SNE use:\n",
                "# from sklearn.manifold import TSNE\n",
                "\n",
                "# for UMAP first install the package: \n",
                "# pip install umap-learn\n",
                "# import umap\n",
                "\n",
                "# ADD YOUR CODE HERE\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "#### Part 3:\n",
                "\n",
                "Discuss your findings. Can you explain why some of the embeddings are more similar than others? Do some of the similarities make less sense than others?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 3 - Sentence Embeddings\n",
                "You will analyze the following four sentences:\n",
                "1. If a tree falls in a forest and no one is around to hear it, does it make a sound?\n",
                "2. A tree is an abstract data model consisting of a root, internal nodes, leaves, and path branches.\n",
                "3. In autumn, leaves will slowly fall from the branches towards the roots, covering the path below.\n",
                "4. If a graph is a tree, all node pairs are connected by exactly one path which traverses the root node.\n",
                "\n",
                "### Part 1:\n",
                "Compute sentence embeddings of the given four sentences with a pre-trained BERT model (use the same model as in Task 2). \n",
                "To retrieve sentence embeddings, extract the representation of the [CLS] token from the final layer (i.e., layer 12).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# TODO - ADD YOUR CODE HERE\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part 2:\n",
                "Compute sentence embeddings of the same sentences by averaging the word2vec word embeddings of all words in the sentence (similar to Assignment 6)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# TODO - ADD YOUR CODE HERE\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part 3: \n",
                "Repeat the process described in Part 2, but remove stop words before averaging the word2vec embeddings to create the sentence representation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# TODO - ADD YOUR CODE HERE\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part 4:\n",
                "Separately compute the pairwise cosine similarities between all four sentence embeddings in each model. \n",
                "That is, compute cosine similarities between \n",
                "\n",
                "(1) all sentence embeddings generated by BERT, \n",
                "\n",
                "(2) all sentence embeddings generated by word2vec with stop words, and \n",
                "\n",
                "(3) all sentence embeddings generated by word2vec without stop words \n",
                "\n",
                "(you **do not** need to compare the embeddings **between different models**!). \n",
                "\n",
                "Display your results in a table with 5 columns: SentenceID1, SentenceID2, cosine BERT, cosine w2v, cosine w2v-stopwords."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# TODO - ADD YOUR CODE HERE\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "### Part 5:\n",
                "Discuss the results. Which differences in sentence similarities make sense? Can you explain why?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "#### Submitting your results:\n",
                "\n",
                "To submit your results, please:\n",
                "\n",
                "- save this file, i.e., `ex??_assignment.ipynb`.\n",
                "- if you reference any external files (e.g., images), please create a zip or rar archive and put the notebook files and all referenced files in there.\n",
                "- login to ILIAS and submit the `*.ipynb` or archive for the corresponding assignment."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Remarks:**\n",
                "    \n",
                "- Do not copy any code from the Internet. In case you want to use publicly available code, please, add the reference to the respective code snippet.\n",
                "- Check your code compiles and executes, even after you have restarted the Kernel.\n",
                "- Submit your written solutions and the coding exercises within the provided spaces and not otherwise.\n",
                "- Write the names of your partner and your name in the top section."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "rita",
            "language": "python",
            "name": "rita"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        },
        "pycharm": {
            "stem_cell": {
                "cell_type": "raw",
                "metadata": {
                    "collapsed": false
                },
                "source": []
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
