{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Document Analysis: Computational Methods - Summer Term 2025\n",
                "### Lectures: Jun.-Prof. Dr. Andreas Spitz\n",
                "### Tutorials: Julian Schelb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exercise 9"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### You will learn about:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this exercise, you will implement three custom classifiers for sentiment analysis in movie reviews and evaluate them. As a dataset, use the polarity dataset (v2): \n",
                "http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz. \n",
                "The data contains 1000 negative and 1000 positive movie reviews.\n",
                "\n",
                "As a first step, split the data into a training set (900 negative and 900 positive reviews) and a test set (the remaining 200 reviews). \n",
                "Add labels to the data (0 for negative reviews, 1 for positive reviews). \n",
                "Make sure to shuffle both data sets. You will be using the same training and test data for all tasks.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# your code goes here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## Task 1: Rule-based Sentiment Classifier\n",
                "\n",
                "Inspect positive and negative reviews in your training set and create a set of 10 rules for sentiment classification. \n",
                "You may also look at word counts and word distributions for positive and negative reviews in your training data (or their differences) to come up with rules. \n",
                "All rules should be encoded as regular expressions that either match or fail to match a text string. \n",
                "Combine your rules in a **ClassifySentimentRB('string')** function that outputs 0 if the sentiment of the input string is negative and 1 if the sentiment is positive.\n",
                "Run your function on the test set, then compute the accuracy of your classifier and the confusion matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# your code goes here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## Task 2 - Naive Bayes Sentiment Classifier\n",
                "\n",
                "Implement a Naive Bayes classifier for sentiment classification and train it on word frequency features derived from the training data. \n",
                "You may use an existing Naive Bayes implementation (for example: https://scikit-learn.org/stable/modules/naive_bayes.html), but make sure to optimize it by engineering good features! \n",
                "Consider which preprocessing steps might be helpful and which might harm the performance, e.g. stopword removal or stemming. \n",
                "Wrap your code in a function **ClassifySentimentNB('string')** that outputs 0 if the sentiment of the input string is negative and 1 if the sentiment is positive.\n",
                "Use the test set to evaluate your Naive Bayes sentiment classifier. \n",
                "Compute the accuracy of your classifier and the confusion matrix.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# your code goes here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 3: Neural Sentiment Classification\n",
                "\n",
                "Implement a neural sentiment classifier by fine-tuning DistilBERT model https://huggingface.co/docs/transformers/model_doc/distilbert . \n",
                "Use the training set as input for fine-tuning a model that is using a classification layer as the final layer. \n",
                "Make sure to fine-tune your classifier sufficiently (that is, run it for multiple epochs and check for convergence). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "\n",
                "# this time, we will work with distilbert -- a distilled version of BERT (it is smaller, faster, and cheaper)\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
                "# ...and we use an architecture that is specifically developed for the classification task; \n",
                "# here, we specify that our training data will have 2 labels, i.e., 0 for the negative sentiment and 1 for the positive sentiment\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2) \n",
                "\n",
                "# the input review can be max 512 tokens long\n",
                "max_length = 512"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that some reviews may exceed the input token limit of your model. \n",
                "You may truncate reviews (=removing tokens at the end of the review that would exceed the limit) \n",
                "or experiment with alternate approaches (e.g., truncating from the middle to keep beginning and end, or splitting reviews into three sections and using majority voting, etc.). \n",
                "If you need to use a validation set, make sure to split it from your training data - do not use the test data for validation.\n",
                "Evaluate your neural classifier on the test. Compute the accuracy of your classifier and the confusion matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "is_executing": false,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# prepare the training and test data here (and the validation data, if needed)\n",
                "# tokenize the dataset, and deal with reviews that are longer than 512 tokens"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# specify the parameters for learning, \n",
                "# train the model, \n",
                "# and evaluate it\n",
                "\n",
                "# REMARK: you CAN use and extend this code, or write your own code from scratch! (whatever is easier for you)\n",
                "# you can get some hints here: https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python\n",
                "from transformers import Trainer, TrainingArguments\n",
                "\n",
                "# these are just default settings, adapt them as needed\n",
                "training_args = TrainingArguments(\n",
                "    # specify your training arguments here\n",
                ")\n",
                "\n",
                "trainer = Trainer(\n",
                "    # specify your trainer here\n",
                ")\n",
                "\n",
                "# train the model\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Task 4: Error Analysis\n",
                "For each of the above classifiers, randomly select 10 misclassified reviews (false positives or false negatives) and manually inspect them. \n",
                "Can you determine trends in the errors that the models make? \n",
                "Discuss your findings and the relative performances of the three sentiment classifiers that you implemented in Tasks 1-3.\n",
                "\n",
                "\n",
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>\n",
                "\n",
                "\n",
                "#### Submitting your results:\n",
                "\n",
                "To submit your results, please:\n",
                "\n",
                "- save this file, i.e., `ex??_assignment.ipynb`.\n",
                "- if you reference any external files (e.g., images), please create a zip or rar archive and put the notebook files and all referenced files in there.\n",
                "- login to ILIAS and submit the `*.ipynb` or archive for the corresponding assignment."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Remarks:**\n",
                "    \n",
                "- Do not copy any code from the Internet. In case you want to use publicly available code, please, add the reference to the respective code snippet.\n",
                "- Check your code compiles and executes, even after you have restarted the Kernel.\n",
                "- Submit your written solutions and the coding exercises within the provided spaces and not otherwise.\n",
                "- Write the names of your partner and your name in the top section."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "rita",
            "language": "python",
            "name": "rita"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        },
        "pycharm": {
            "stem_cell": {
                "cell_type": "raw",
                "metadata": {
                    "collapsed": false
                },
                "source": []
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
