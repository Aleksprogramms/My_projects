{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Document Analysis: Computational Methods - Summer Term 2025\n",
                "### Lectures: Jun.-Prof. Dr. Andreas Spitz\n",
                "### Tutorials: Julian Schelb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exercise 06"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### You will learn about:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Word Embeddings (word2vec)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 1 - Word2Vec:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part 1:\n",
                "Explain the difference between the continuous bag of words (CBOW) and Skip-Gram versions of word2vec."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "CBOW is a type of training in which computer learn to predict a missing word. \\\n",
                "Skip-gram is training in which computer tries to predict the context.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part 2: \n",
                "Given the sentence \"You shall know a word by the company it keeps\" and a sliding window size of l=5 (two to the left, two to the right), generate a list of all positive training data (input and output) that\n",
                "\n",
                "a) CBOW creates for the word \"company\".\n",
                "\n",
                "b) Skip-Gram creates for the word \"word\"."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You shall know a word by the company it keeps\n",
                "\n",
                "a) \n",
                "\n",
                "input       output\n",
                "\n",
                "word        the\n",
                "\n",
                "by          the \n",
                "\n",
                "company     the \n",
                "\n",
                "it          the\n",
                "\n",
                "by          company\n",
                "\n",
                "the         company\n",
                "\n",
                "it          company\n",
                "\n",
                "keeps       company\n",
                "\n",
                "\n",
                "b)\n",
                "\n",
                "input       output\n",
                "\n",
                "shall       a\n",
                "\n",
                "know        a\n",
                "\n",
                "word        a\n",
                "\n",
                "by          a\n",
                "\n",
                "know        a\n",
                "\n",
                "a           a\n",
                "\n",
                "by          a\n",
                "\n",
                "the         a\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 2 - Similarity:\n",
                "\n",
                "### Part 1:\n",
                "Given The following 5-dimensional vector embeddings for three words, manually compute cosine similarities to determine whether a boat is more similar to an apple or to an orange.\n",
                "\n",
                "apple = [1,5,3,3,2]\n",
                "\n",
                "orange = [2,5,2,4,2]\n",
                "\n",
                "boat = [6,1,8,4,2]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "apple/boat = (1 * 6 + 5 * 1 +  3 * 8 + 3 * 4 + 2 * 2) / (1 + 25 + 9 + 9 + 4)^0.5 * (36 + 1 + 64 + 16 + 4) = (51)/ (48 * 121)^0.5 \n",
                "\n",
                "orange / boat = (2 * 6 + 5 * 1 + 2 * 8 + 4 * 4 + 4)/ (4 + 25 + 4 + 16 + 5)^0.5 * (121) ^ 0.5 = (53) / (54 * 121)^ 0.5 "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "---\n",
                "\n",
                "#### Part 2:\n",
                "\n",
                "What are the implications of being able to compute arbitrary pairwise word similarities as in the example above?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1) Better semantical search (synonyms: car, automobile)\n",
                "2) Better IR search: doctor, also psysician\n",
                "3) Clustering in semantical groups\n",
                "4) Pos-tag, NER, machine translation, also use it "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "#### Part 3:\n",
                "\n",
                "Using a pre-trained word2vec model from gensim package, investigate the claim that embeddings encode semantic relations via compositional semantics, such als \"king - man + woman = queen\". For each of the following examples, use the model to generate the three input vectors, compute the target vector, and retrieve the 10 most similar words by cosine similarity. Discuss your findings.\n",
                "\n",
                "Examples:\n",
                "\n",
                "- king - man + woman\n",
                "- France - Paris + Tokyo\n",
                "- sister - brother + grandson\n",
                "- bigger - big + cold\n",
                "- scientist - Einstein + Picasso"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": false,
                "jupyter": {
                    "outputs_hidden": false
                },
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'gensim'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load pre-trained word2vec\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# you first need to download the bin file of the model, do not submit this file!!! since it will be larger than 1GB\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors\n\u001b[32m      5\u001b[39m model = KeyedVectors.load_word2vec_format(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpath_to_the_binary_file\u001b[39m\u001b[33m'\u001b[39m, binary=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# TODO - ADD YOUR CODE HERE\u001b[39;00m\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gensim'"
                    ]
                }
            ],
            "source": [
                "# load pre-trained word2vec\n",
                "# you first need to download the bin file of the model, do not submit this file!!! since it will be larger than 1GB\n",
                "\n",
                "from gensim.models import KeyedVectors\n",
                "model = KeyedVectors.load_word2vec_format(r'path_to_the_binary_file', binary=True)\n",
                "\n",
                "\n",
                "# TODO - ADD YOUR CODE HERE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Task 3 - Embedding Visualization:\n",
                "\n",
                "### Part 1:\n",
                "Your task is to calculate the pair-wise similarities between the first 500 critics of the 'rottentomatoes' dataset from the earlier assignment (this time work on single critics, i.e., sentences).\n",
                "Calculate the pairwise similarity between their average word2vec embedding vectors and visualize the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "jupyter": {
                    "outputs_hidden": false
                },
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# TODO - ADD YOUR CODE HERE\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Submitting your results:\n",
                "\n",
                "To submit your results, please:\n",
                "\n",
                "- save this file, i.e., `ex??_assignment.ipynb`.\n",
                "- if you reference any external files (e.g., images), please create a zip or rar archieve and put the notebook files and all referenced files in there.\n",
                "- login to ILIAS and submit the `*.ipynb` or archive for the corresponding assignment."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Remarks:**\n",
                "    \n",
                "- Do not copy any code from the Internet. In case you want to use publicly available code, please, add the reference to the respective code snippet.\n",
                "- Check your code compiles and executes, even after you have restarted the Kernel.\n",
                "- Submit your written solutions and the coding exercises within the provided spaces and not otherwise.\n",
                "- Write the names of your partner and your name in the top section."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        },
        "pycharm": {
            "stem_cell": {
                "cell_type": "raw",
                "metadata": {
                    "collapsed": false
                },
                "source": []
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
