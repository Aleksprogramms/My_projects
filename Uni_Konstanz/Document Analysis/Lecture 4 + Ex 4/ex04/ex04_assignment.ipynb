{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "9edfbc7b",
            "metadata": {},
            "source": [
                "## Document Analysis: Computational Methods - Summer Term 2025\n",
                "### Lectures: Jun.-Prof. Dr. Andreas Spitz\n",
                "### Tutorials: Julian Schelb"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b5fe5c1e",
            "metadata": {},
            "source": [
                "# Exercise 04"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c5fc5949",
            "metadata": {},
            "source": [
                "- NLP Recap\n",
                "- Entity Recognition"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "38240a1f",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4f62eba3",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Task 1 - NLP Recap:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "27cd210b",
            "metadata": {
                "jupyter": {
                    "source_hidden": true
                },
                "tags": []
            },
            "source": [
                "## Q & A\n",
                "\n",
                "Give answers to the following question. If you like, you can treat it as exam preparation, e.g., first try to solve the question without help of the slides ;) But you are obviously allowed to use the slides at any time\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b94e2d70",
            "metadata": {},
            "source": [
                "(1) Name three reasons why natural language processing (NLP) is challenging"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "50419894",
            "metadata": {},
            "source": [
                "1. Because some of the words have more than one POS-tag(Heteronims)\n",
                "2. To predict a POS-tag we need not only statical algorithms, but more advanced\n",
                "3. If a corpus don't have enough words, than it will be bad trained (Unigramm, Bigramm)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f074a9f0",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4ccec244",
            "metadata": {},
            "source": [
                "(2) What is tokenization?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f981b551",
            "metadata": {},
            "source": [
                "Tokenization is a process of breaking text into smaller units called tokens(typically words, subwords, or punctuation marks), which serve as the basic elements for further NLP tasks."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "114dca55",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "934b6559",
            "metadata": {},
            "source": [
                "(3) What is a word stem? Give the stem of the word \"undoes\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "41b7096e",
            "metadata": {},
            "source": [
                "Word stem is the core part of a word that remains after removing inflectional or derivational affixes.\n",
                "\n",
                "Undoes -> Undo"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5592f81f",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "10e6aa99",
            "metadata": {},
            "source": [
                "(4) What is a word lemma? Give the lemma of the word \"undoes\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d70dbb28",
            "metadata": {},
            "source": [
                "Lemma is a canonical or dictionary from of a word - the form like in dictionary.\n",
                "\n",
                "Undoes -> Undo"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "58671134",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6af49695",
            "metadata": {
                "tags": []
            },
            "source": [
                "(5) Why should we typically extract word stems/lemmas before preceding with text analysis?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "26f7007f",
            "metadata": {},
            "source": [
                "Because they might help us to filter texts or documents.\n",
                "\n",
                "They reduce vocabulary size and helps algorithms work more efficiently.\n",
                "\n",
                "Improves accuracy in tasks like information retrieval, classification, and clustering, because semantically related forms are grouped together."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "094292f7",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b4a4f7aa",
            "metadata": {},
            "source": [
                "(6) What are stop-words? Why it makes sense to remove stop-words before preceding with text analysis?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "03de88c4",
            "metadata": {},
            "source": [
                "Stop-words are frequent dunction words (like  the, is, and). We remove them to reduce noise, vocabulary size, and improves efficiency and accuracy of text analysis.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a119ae62",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7493dfd1",
            "metadata": {},
            "source": [
                "(7) If you had access to frequency statistics for a language, how could you create a list of stop words?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7c1dced2",
            "metadata": {},
            "source": [
                "We can make a list of stop words, by using Zipf's Law"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ab068e2c",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6605debd",
            "metadata": {},
            "source": [
                "(8) Name a use-case in which we should NOT remove stop-words prior to text analysis."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c58bbb6d",
            "metadata": {},
            "source": [
                "POS-tagging"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a641d836",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99d1855b",
            "metadata": {},
            "source": [
                "(9) What is part-of-speech (POS) tagging? Why is it useful?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85c19281",
            "metadata": {},
            "source": [
                "Part-of-speech tagging is proccess of assinging tags(grammatical categories) to words. It is useful for future text/senctece processing like Named-Entity-recognition"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "45edd1d8",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b782d611",
            "metadata": {},
            "source": [
                "(10) Explain how n-gram POS tagging works. What is the limitation of this method?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7423a5e0",
            "metadata": {},
            "source": [
                "N-gram tagging uses statistical approach to tag words depending on previous corpus. Limitation is that, without previous context and without backoff stategy it woeks bad. "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ce7f413f",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "224e62ac",
            "metadata": {},
            "source": [
                "(11) What is parsing? Which two main types of parsing exist?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "912f9049",
            "metadata": {},
            "source": [
                "Parsing is an algorithm of building a syntactical structure of a senctece with the respect of given grammar. Two types are Bottom-up and Top-down approaches."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7e9b5c25",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8900c79f",
            "metadata": {},
            "source": [
                "(12) What is the difference between a context-free and a context-sensitive language? What is the difference between a context-free and a regular language?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c5d2b06",
            "metadata": {},
            "source": [
                "CFL vs CSL: Context-sensitive rules allow rewiriting depending on surrounding symbols; they generate a larger class of languages \\\n",
                "CFL vs Regular: Regular languages are simple(no recursion); all regular languages are CFLs, but not all CFLs are regular. "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "09dcf220",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "46441c44",
            "metadata": {},
            "source": [
                "(13) Give an equivalent grammar in Chomsky Normal form for the Grammar G=(N,T,P,S) with N={S,A,B,C}, T={a,b,c}, P={S->ABC, A->a, B->b, C->c}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a072fc99",
            "metadata": {},
            "source": [
                "G = (N, T, P, S) \\\n",
                "N = {S, A, B, C} \\\n",
                "T = {a,b,c} \\\n",
                "P = {S->ABC, A->a, B->b, C->c} \\"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "becf2901",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "799529c6",
            "metadata": {},
            "source": [
                "(14) Explain how shift-reduce parsing works."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3cde835a",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit)</font>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "565c26d0",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d573a0eb",
            "metadata": {},
            "source": [
                "(15) What is the grammar ambiguity problem?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fb46149f",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit)</font>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "645d5351",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0bb4506f",
            "metadata": {},
            "source": [
                "## Task 2 - Named Entity Recognition:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc81306c",
            "metadata": {
                "tags": []
            },
            "source": [
                "### Part 1: Automated Annotations\n",
                "\n",
                "Use Spacy to annotate entities in the debates dataset (available as part of the JSON in the data directory). [Depending on your computer, the extraction may take some time. Therefore, you are allowed to restrict the size of the text, e.g. to the first 250 sentences. Feel free to use a larger share of data to get better insights.]\n",
                "\n",
                "Tip: Use the en_core_web_sm corpus\n",
                "\n",
                "Display the results in readable form, e.g. show the tagged entities for a reasonably sized part of the data, idealy alongside the original text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "f46aad15",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "hello\n"
                    ]
                }
            ],
            "source": [
                "# Tip for Spacy: In order to load a dataset, you might need to download the dataset via command line. \n",
                "#Inside of a notebook, you can run commands with a !-mark\n",
                "\n",
                "#Similar to: !python ...\n",
                "!python -m spacy "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7ee8ac24",
            "metadata": {},
            "outputs": [],
            "source": [
                "# read debates\n",
                "import json\n",
                "with open('data/texts.json', 'r') as infile:\n",
                "    data = json.load(infile)\n",
                "\n",
                "content_debates = data['debates']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "736d6871",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your Code Submission goes here"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c716f922",
            "metadata": {},
            "source": [
                "### Part 2: Analysis\n",
                "\n",
                "In real-word use cases, NER can be difficult. Analyze the following challenging examples and identify all cases in which the automated NER failed. For the tagging, you can use the method from part 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "15286f4b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# read debates\n",
                "import json\n",
                "with open('data/hard_data.json', 'r') as infile:\n",
                "    data = json.load(infile)\n",
                "\n",
                "test_sentences = [s[\"sentence\"] for s in data['test_sentences']]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e76fc6a",
            "metadata": {},
            "source": [
                "Write the failure cases down here, then try to classify them into types of errors that the model makes. Discuss the results.\n",
                "You can use a mixture of markdown and code if it suits your analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6acb81f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Your Code Submission goes here"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3caa1823",
            "metadata": {},
            "source": [
                "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) </font>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0eb591d2",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fafba55f",
            "metadata": {},
            "source": [
                "#### Submitting your results:\n",
                "\n",
                "To submit your results, please:\n",
                "\n",
                "- save this file, i.e., `ex??_assignment.ipynb`.\n",
                "- if you reference any external files (e.g., images), please create a zip or rar archieve and put the notebook files and all referenced files in there.\n",
                "- login to ILIAS and submit the `*.ipynb` or archive for the corresponding assignment."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "219fb29a",
            "metadata": {},
            "source": [
                "**Remarks:**\n",
                "    \n",
                "- Do not copy any code from the Internet. In case you want to use publicly available code, please, add the reference to the respective code snippet.\n",
                "- Check your code compiles and executes, even after you have restarted the Kernel.\n",
                "- Submit your written solutions and the coding exercises within the provided spaces and not otherwise.\n",
                "- Write the names of your partner and your name in the top section."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
