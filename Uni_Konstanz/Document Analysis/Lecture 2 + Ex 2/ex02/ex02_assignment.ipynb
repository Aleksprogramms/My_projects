{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83cf750-33a5-4457-9a8c-4b13b4c44cd4",
   "metadata": {},
   "source": [
    "## Document Analysis: Computational Methods - Summer Term 2025\n",
    "### Lectures: Jun.-Prof. Dr. Andreas Spitz\n",
    "### Tutorials: Julian Schelb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675e5c2-c60f-43e9-9076-a3bf7a36ffa1",
   "metadata": {},
   "source": [
    "# Exercise 02\n",
    "\n",
    "You will learn about:\n",
    "    \n",
    "- The Brown Corpus\n",
    "- Part of Speech (POS) tagging\n",
    "- Unigram and Bigram tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd621e3-4f8e-4fbb-88e2-8910fca352ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b77e4-4f2e-4441-85e3-5a007faa73c7",
   "metadata": {},
   "source": [
    "## Task 1 - The Brown Corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbabdb-28ad-414c-b4fd-5d8e244e793a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42de428-53b6-4a0e-8311-3ecd0dafa6d7",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "In the following, we will use the _Brown Corpus_. In one or two sentences, describe what the _Brown Corpus_ is and how it can be used for POS tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0ae3b-f490-4174-bc99-b02760f5e197",
   "metadata": {},
   "source": [
    "\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - expected approx. 50-100 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09200db1-e168-4173-a85e-92c5630ddabc",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "We start by analyzing which tags occur in the brown corpus. For this, you should extract the `tagged_words` first. Then\n",
    "\n",
    "1. List the first 20 entries and\n",
    "2. then list the ten most common tags in the category `news`.\n",
    "\n",
    "In the lecture, we use the Brown Corpus POS tags (default, i.e., `tagset=None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48b5e71-e2ed-4b57-af65-f352d0873632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\bagim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bfca02e-0ed1-46ca-a0e7-b37b819d7c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS')]\n",
      "[('The', 'UNK'), ('Fulton', 'UNK'), ('County', 'UNK'), ('Grand', 'UNK'), ('Jury', 'UNK'), ('said', 'UNK'), ('Friday', 'UNK'), ('an', 'UNK'), ('investigation', 'UNK'), ('of', 'UNK')]\n"
     ]
    }
   ],
   "source": [
    "print(brown.tagged_words()[:20])\n",
    "print(brown.tagged_words(tagset= \"news\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02186ccd-c25c-4788-8cd3-d4bc636ad93e",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "In the previous part, you should get ten different POS tags. For each tag, what does it stand for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9703d-5e72-40d9-a220-ccd2bac2e5f9",
   "metadata": {},
   "source": [
    "\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - expected: explanation for each tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6adb6-1284-4ad3-87b7-b2d3ba5ffbea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab5f72-7433-4338-8f7f-2ab002c03074",
   "metadata": {},
   "source": [
    "## Task 2 - POS Tagging:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c060a2-003d-47a7-a929-e08c940b7389",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "Use a Unigram tagger, trained on the Brown corpus, to tag the example sentence from the Penn treebank (see also https://www.nltk.org/_modules/nltk/corpus/reader/tagged.html)\n",
    "\n",
    "For which words does it completely fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a5acd4-6ab3-494b-a08b-6992b2a0919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\bagim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\bagim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d492dec-b7b7-4c86-92e8-f3873221dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.', 'Mr.', 'Vinken']\n"
     ]
    }
   ],
   "source": [
    "treebank_test = list(nltk.corpus.treebank.words()[0:20])\n",
    "print(treebank_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd7eed60-2a56-4ce9-a0af-cae2eccb987a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mUnigramTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreebank_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\tag\\sequential.py:363\u001b[39m, in \u001b[36mUnigramTagger.__init__\u001b[39m\u001b[34m(self, train, model, backoff, cutoff, verbose)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, train=\u001b[38;5;28;01mNone\u001b[39;00m, model=\u001b[38;5;28;01mNone\u001b[39;00m, backoff=\u001b[38;5;28;01mNone\u001b[39;00m, cutoff=\u001b[32m0\u001b[39m, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\tag\\sequential.py:296\u001b[39m, in \u001b[36mNgramTagger.__init__\u001b[39m\u001b[34m(self, n, train, model, backoff, cutoff, verbose)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(model, backoff)\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\tag\\sequential.py:179\u001b[39m, in \u001b[36mContextTagger._train\u001b[39m\u001b[34m(self, tagged_corpus, cutoff, verbose)\u001b[39m\n\u001b[32m    177\u001b[39m fd = ConditionalFreqDist()\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m tagged_corpus:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     tokens, tags = \u001b[38;5;28mzip\u001b[39m(*sentence)\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m index, (token, tag) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentence):\n\u001b[32m    181\u001b[39m         \u001b[38;5;66;03m# Record the event.\u001b[39;00m\n\u001b[32m    182\u001b[39m         token_count += \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "print(UnigramTagger(treebank_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b2244-39c2-4139-90c2-f63b8f1004e0",
   "metadata": {},
   "source": [
    "\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - expected list of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49def5-67ab-40e2-a795-28e96acddb1f",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Compare the tags with the reference tags from the Penn treebank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ceed1-3121-4580-b277-223c381167ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE SUBMISSION ANSWER HERE (Double click to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13abc46-aebe-41d1-ba16-29edc535e942",
   "metadata": {},
   "source": [
    "\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - expected comparison for each tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9781814-a8ac-4d0f-a884-189cb65492cd",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Now train \n",
    " 1. a Unigram tagger,\n",
    " 2. a Bigram tagger,\n",
    " 3. and a Brill tagger (using rule brill24)\n",
    " \n",
    "with a subset of the Brown Corpus. This might take 1-2 minutes.\n",
    "\n",
    "Then, validate and compare their performance on a different subset of the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f019a5-0973-4268-bc65-e819a1722be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger, BigramTagger\n",
    "from nltk.tag.brill_trainer import BrillTaggerTrainer\n",
    "from nltk.tag.brill import brill24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c764526-7add-4c98-b216-fb57e9a8fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cutoff = 20000\n",
    "brown_sents_train = brown.tagged_sents()[0:n_cutoff] # training corpus\n",
    "brown_sents_test = brown.tagged_sents()[n_cutoff:] # reference corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1d093-a53c-45dc-b4c5-78b20afb3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE SUBMISSION ANSWER HERE (Double click to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f97769-7af9-4f27-afab-3353272230de",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "Discuss the scores of your taggers. Which one performs better, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0cb08-2647-4f55-948f-a65d4206a801",
   "metadata": {},
   "source": [
    "\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - expected approx. 100-150 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627484d-9018-4846-8574-c46ea15f0b67",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "\n",
    "Discuss ideas for improving the implementations and the quality of the taggers. You are not required to implement the improvement ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a3013-e28e-4acc-a5c3-5e1fd7a80005",
   "metadata": {},
   "source": [
    "\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - expected approx. 100-250 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aded10e-f01a-44c0-8f78-b9318426fd33",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f867e-c1f9-4d71-be99-3204b3658f85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3 - Unigram and Bigram Taggers (pen and paper):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b9b940-bb2a-4e1e-8353-a1bd7d0a736f",
   "metadata": {},
   "source": [
    "**Training data:**\n",
    "\n",
    "His [PRP] raise [NN] was [VB] five [CD] dollars [NN] . [SYM]\n",
    "We [PRP] usually [RB] get [VB] a [DT] raise [NN] at [IN] the [DT] start [NN] of [IN] the [DT] year [NN] . [SYM]\n",
    "A [DT] major [JJ] success [NN] helped [VB] to [TO] raise [VB] our [PRP] spirits [NN] . [SYM]\n",
    "\n",
    "\n",
    "\n",
    "**Test sentence:**\n",
    "\n",
    "It [PRP] looks [VB] like [CC] a [DT] fine [JJ] place [NN] to [TO] raise [NN or VB?] children [NN] . [SYM]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd51b7-800a-4fc1-a69b-4faa049a82c9",
   "metadata": {},
   "source": [
    "### Part 1: Unigram Tagger\n",
    "\n",
    "Given the training data, determine the most likely tag for the word \"raise\" in the test sentence, using Unigram tagging method:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc77aa4-789e-4483-8656-0a2296e8058a",
   "metadata": {},
   "source": [
    "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - write down the steps for calculating the most likely POS tag</font>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae00231-a0cd-44c6-97b0-fa444e237d57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 2 - Bigram Tagger:\n",
    "\n",
    "Given the training data (in Task 3), determine the most likely tag for the word \"raise\" in the test sentence, using Bigram tagging method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba02ef-c4e1-4ede-aa3a-b03c92aa5f33",
   "metadata": {},
   "source": [
    "<font color='ff000000'>\\# TEXT SUBMISSION ANSWER HERE (Double click to edit) - write down the steps for calculating the most likely POS tag</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f649cb9-cd57-43cd-b27c-3cef5fbf9115",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4717fe7-44f7-4446-a698-e3564228a265",
   "metadata": {},
   "source": [
    "#### Submitting your results:\n",
    "\n",
    "To submit your results, please:\n",
    "\n",
    "- save this file, i.e., `ex??_assignment.ipynb`.\n",
    "- if you reference any external files (e.g., images), please create a zip or rar archieve and put the notebook files and all referenced files in there.\n",
    "- login to ILIAS and submit the `*.ipynb` or archive for the corresponding assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b6bc4-1fee-4efe-9a1a-657ec6eab062",
   "metadata": {},
   "source": [
    "**Remarks:**\n",
    "    \n",
    "- Do not copy any code from the Internet. In case you want to use publicly available code, please, add the reference to the respective code snippet.\n",
    "- Check your code compiles and executes, even after you have restarted the Kernel.\n",
    "- Submit your written solutions and the coding exercises within the provided spaces and not otherwise.\n",
    "- Write the names of your partner and your name in the top section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df879020-f06b-4172-9ac4-8e0f7bda365a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
